{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "->Explore the example data of Dogs vs. Cats\n",
        "\n",
        "->Build and train a neural network to classify between the two pets\n",
        "\n",
        "->Evaluate the training and validation accuracy\n",
        "\n",
        "->Transfer learning- using prebuilt convolution layers of one model"
      ],
      "metadata": {
        "id": "NHEN9HM1_xtn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDMJ3173y__t"
      },
      "outputs": [],
      "source": [
        "!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
        "\n",
        "import zipfile\n",
        "\n",
        "local_zip='./cats_and_dogs_filtered.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r').extractall()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "base_dir='cats_and_dogs_filtered'\n",
        "\n",
        "train_dir=os.path.join(base_dir,'train')\n",
        "validation_dir=os.path.join(base_dir,'validation')\n",
        "\n",
        "train_cats_dir=os.path.join(train_dir,'cats')\n",
        "train_dogs_dir=os.path.join(train_dir,'dogs')\n",
        "\n",
        "validation_cats_dir=os.path.join(validation_dir,'cats')\n",
        "validation_dogs_dir=os.path.join(validation_dir,'dogs')"
      ],
      "metadata": {
        "id": "oEC0eYdK06p3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nrows=4\n",
        "ncols=4\n",
        "\n",
        "pic_index=0\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=8\n",
        "train_cat_fnames = os.listdir( train_cats_dir )\n",
        "train_dog_fnames = os.listdir( train_dogs_dir )\n",
        "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
        "                for fname in train_cat_fnames[ pic_index-8:pic_index] \n",
        "               ]\n",
        "\n",
        "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
        "                for fname in train_dog_fnames[ pic_index-8:pic_index]\n",
        "               ]\n",
        "\n",
        "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cQSkZI7k2nZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# model=tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(512,activation='relu'),\n",
        "#     tf.keras.layers.Dense(1,activation='sigmoid'),  \n",
        "# ])\n",
        "# model.summary()\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model= InceptionV3(input_shape=(150,150,3),\n",
        "                               include_top=False,\n",
        "                               weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer=pre_trained_model.get_layer('mixed7')\n",
        "print('Last layer output shape: ',last_layer.output_shape)\n",
        "last_output=last_layer.output"
      ],
      "metadata": {
        "id": "5vMCmIwq3Whm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "x=layers.Flatten()(last_output)\n",
        "\n",
        "x=layers.Dense(1024,activation='relu')(x)\n",
        "\n",
        "x=layers.Dropout(0.2)(x)\n",
        "\n",
        "x=layers.Dense(1,activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x) "
      ],
      "metadata": {
        "id": "93UdLuqJGVU7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "JHNAyPg84489"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator( \n",
        "    rescale = 1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "test_datagen  = ImageDataGenerator( \n",
        "    rescale = 1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))"
      ],
      "metadata": {
        "id": "JyricoCu5ZWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=50,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "r_N_uhU26REV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path='/content/' + fn\n",
        "  img=load_img(path, target_size=(150, 150))\n",
        "  \n",
        "  x=img_to_array(img)\n",
        "  x /= 255\n",
        "  x=np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(classes[0])\n",
        "  \n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")\n",
        " "
      ],
      "metadata": {
        "id": "1UPkkDWs8q_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}